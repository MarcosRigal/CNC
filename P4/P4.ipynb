{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Práctica 4: Clasificación semi-supervisada\n",
                "\n",
                "En esta práctica exploraremos **clasificación semi-supervisada**, un enfoque que combina datos **etiquetados** y datos **no etiquetados** para mejorar el rendimiento de nuestros modelos.\n",
                "\n",
                "## Objetivos\n",
                "1. **Tarea 1**: Implementar un método de clasificación semi-supervisada (por ejemplo, *self-training*).\n",
                "2. **Tarea 2**: Comparar al menos dos métodos disponibles en librerías (por ejemplo, *Label Propagation* y *Label Spreading*) en tres datasets.\n",
                "\n",
                "Empezaremos con un breve repaso de conceptos, y luego desarrollaremos las secciones solicitadas."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## 1. Breve repaso teórico\n",
                "La **clasificación semi-supervisada** busca aprovechar la gran cantidad de datos no etiquetados para mejorar la capacidad de generalización de un modelo. La idea principal es que, si contamos con pocas etiquetas pero tenemos muchos ejemplos sin etiquetar, podemos iterativamente asignar pseudo-etiquetas (cuando estemos razonablemente seguros) y así expandir nuestro conjunto etiquetado.\n",
                "\n",
                "### Principales enfoques\n",
                "- **Self-training**: Entrenamos un clasificador con los datos etiquetados y predecimos sobre los no etiquetados. Agregamos al conjunto de entrenamiento aquellos ejemplos cuya predicción sea más confiable.\n",
                "- **Label Propagation** y **Label Spreading** (métodos *graph-based*): Construyen un grafo de similitud entre instancias y propagan las etiquetas de los ejemplos etiquetados a sus vecinos más cercanos.\n",
                "- **Co-training**: Entrena dos (o más) clasificadores con diferentes subconjuntos de características (o vistas) y cada uno va etiquetando para el otro.\n",
                "- **S3VM**: Extensión semi-supervisada de las *Support Vector Machines*, donde los datos no etiquetados contribuyen a maximizar el margen en las regiones de baja densidad.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TAREA 1: Implementación de un método semi-supervisado\n",
                "\n",
                "En esta sección implementamos un método de **Self-Training** en Python, utilizando un clasificador base de scikit-learn (por ejemplo, un **RandomForestClassifier**)."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {
                "tags": []
            },
            "source": [
                "import numpy as np\n",
                "from sklearn.ensemble import RandomForestClassifier\n",
                "\n",
                "def self_training(X_labeled, y_labeled, X_unlabeled, base_classifier, \n",
                "                  confidence_threshold=0.9, max_iter=10):\n",
                "    \"\"\"\n",
                "    Implementación simple de Self-Training.\n",
                "    --------------------------------------------------\n",
                "    X_labeled, y_labeled: Datos (X) y etiquetas (y) para la parte etiquetada.\n",
                "    X_unlabeled: Datos sin etiqueta.\n",
                "    base_classifier: Clasificador supervisado que soporte al menos predict_proba (o predict).\n",
                "    confidence_threshold: Umbral mínimo de probabilidad para aceptar pseudoejemplos.\n",
                "    max_iter: Número máximo de iteraciones.\n",
                "    \"\"\"\n",
                "    X_l = X_labeled.copy()\n",
                "    y_l = y_labeled.copy()\n",
                "    X_u = X_unlabeled.copy()\n",
                "\n",
                "    for iteration in range(max_iter):\n",
                "        # Entrenamos el clasificador con los datos etiquetados\n",
                "        base_classifier.fit(X_l, y_l)\n",
                "\n",
                "        # Predecimos probabilidades sobre el conjunto no etiquetado\n",
                "        if hasattr(base_classifier, \"predict_proba\"):\n",
                "            probs = base_classifier.predict_proba(X_u)\n",
                "            pred_labels = np.argmax(probs, axis=1)\n",
                "            max_probs = np.max(probs, axis=1)\n",
                "        else:\n",
                "            # Si no tiene predict_proba, usamos predict y asumimos confianza=1\n",
                "            pred_labels = base_classifier.predict(X_u)\n",
                "            max_probs = np.ones(len(X_u))\n",
                "\n",
                "        # Seleccionamos las instancias donde la confianza >= confidence_threshold\n",
                "        high_conf_idx = np.where(max_probs >= confidence_threshold)[0]\n",
                "        if len(high_conf_idx) == 0:\n",
                "            # Si no hay instancias con suficiente confianza, detenemos\n",
                "            print(f\"Iteración {iteration}: no se encontraron instancias con confianza >= {confidence_threshold}.\")\n",
                "            break\n",
                "\n",
                "        # Agregamos esas instancias al conjunto etiquetado\n",
                "        X_l = np.vstack([X_l, X_u[high_conf_idx]])\n",
                "        y_l = np.hstack([y_l, pred_labels[high_conf_idx]])\n",
                "\n",
                "        # Quitamos dichas instancias de la lista de no etiquetados\n",
                "        X_u = np.delete(X_u, high_conf_idx, axis=0)\n",
                "\n",
                "        print(f\"Iteración {iteration}: se agregaron {len(high_conf_idx)} instancias con alta confianza.\")\n",
                "\n",
                "    # Al finalizar, retornamos el clasificador entrenado\n",
                "    return base_classifier\n"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "### Ejemplo de uso con datos sintéticos\n",
                "\n",
                "En este ejemplo:\n",
                "- Generamos un dataset sintético con `make_classification`.\n",
                "- Suponemos que solo una parte de las instancias están etiquetadas.\n",
                "- Aplicamos *self-training* para agregar pseudo-etiquetas a los datos no etiquetados.\n",
                "- Finalmente, medimos el desempeño en un conjunto de prueba."
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "from sklearn.datasets import make_classification\n",
                "from sklearn.model_selection import train_test_split\n",
                "from sklearn.metrics import accuracy_score\n",
                "\n",
                "# Generar dataset sintético\n",
                "X, y = make_classification(n_samples=1000, n_features=10, n_informative=3,\n",
                "                           n_classes=2, random_state=42)\n",
                "\n",
                "# Dividir en train/test\n",
                "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
                "\n",
                "# Tomar solo el 20% de y_train como etiquetado\n",
                "labeled_percentage = 0.2\n",
                "num_labeled = int(len(y_train) * labeled_percentage)\n",
                "X_labeled = X_train[:num_labeled]\n",
                "y_labeled = y_train[:num_labeled]\n",
                "X_unlabeled = X_train[num_labeled:]  # no se usan etiquetas para este subconjunto\n",
                "\n",
                "# Entrenar con self-training\n",
                "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
                "self_trained_model = self_training(X_labeled, y_labeled, X_unlabeled, rf,\n",
                "                                   confidence_threshold=0.9,\n",
                "                                   max_iter=10)\n",
                "\n",
                "# Evaluar en el conjunto de prueba\n",
                "y_pred = self_trained_model.predict(X_test)\n",
                "accuracy = accuracy_score(y_test, y_pred)\n",
                "print(\"Exactitud en test después de Self-Training:\", accuracy)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# TAREA 2: Comparación de métodos\n",
                "Para esta tarea:\n",
                "1. Seleccionamos **dos algoritmos** semi-supervisados (por ejemplo, *LabelPropagation* y *LabelSpreading* de scikit-learn).\n",
                "2. Aplicamos cada método a **varios datasets** (idealmente 3 o más) y comparamos resultados.\n",
                "\n",
                "Aquí mostraremos un **ejemplo** con un solo dataset de `scikit-learn` (digits), pero la idea es repetir con más conjuntos de datos (por ejemplo, *Wine*, *Breast Cancer*, etc.) y luego **comparar**.\n"
            ]
        },
        {
            "cell_type": "code",
            "metadata": {},
            "source": [
                "from sklearn.datasets import load_digits\n",
                "from sklearn.semi_supervised import LabelPropagation, LabelSpreading\n",
                "\n",
                "# Cargar dataset (digits)\n",
                "digits = load_digits()\n",
                "X_dig = digits.data\n",
                "y_dig = digits.target\n",
                "\n",
                "# Dividir en train/test\n",
                "X_train_dig, X_test_dig, y_train_dig, y_test_dig = train_test_split(\n",
                "    X_dig, y_dig, test_size=0.3, random_state=42)\n",
                "\n",
                "# Simular que solo un 10% de la parte de entrenamiento está etiquetada\n",
                "num_label_dig = int(0.1 * len(y_train_dig))\n",
                "labels_dig = np.copy(y_train_dig)\n",
                "labels_dig[num_label_dig:] = -1  # usar -1 para indicar sin etiqueta\n",
                "\n",
                "print(f\"Número total de instancias de entrenamiento: {len(y_train_dig)}\")\n",
                "print(f\"Instancias etiquetadas: {num_label_dig}\")\n",
                "print(f\"Instancias no etiquetadas: {len(y_train_dig) - num_label_dig}\")\n",
                "\n",
                "# 1. Label Propagation\n",
                "lp_model = LabelPropagation(kernel='rbf', gamma=20, max_iter=1000)\n",
                "lp_model.fit(X_train_dig, labels_dig)\n",
                "y_pred_lp = lp_model.predict(X_test_dig)\n",
                "acc_lp = accuracy_score(y_test_dig, y_pred_lp)\n",
                "\n",
                "# 2. Label Spreading\n",
                "ls_model = LabelSpreading(kernel='rbf', alpha=0.2, max_iter=1000)\n",
                "ls_model.fit(X_train_dig, labels_dig)\n",
                "y_pred_ls = ls_model.predict(X_test_dig)\n",
                "acc_ls = accuracy_score(y_test_dig, y_pred_ls)\n",
                "\n",
                "print(\"\\nResultados con Label Propagation:\")\n",
                "print(\"Accuracy:\", acc_lp)\n",
                "\n",
                "print(\"\\nResultados con Label Spreading:\")\n",
                "print(\"Accuracy:\", acc_ls)"
            ],
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Discusión de resultados\n",
                "En esta sección se espera:\n",
                "- **Analizar** la precisión (o cualquier otra métrica como F1-score, etc.).\n",
                "- **Comparar** cada método (Label Propagation, Label Spreading) y argumentar por qué uno puede superar a otro.\n",
                "- **Repetir** el procedimiento con otros dos datasets (por ejemplo, [*Wine*](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_wine.html), [*Breast Cancer*](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html)) y mostrar tablas/gráficas de comparación.\n",
                "\n",
                "Al final, se podrían extraer **conclusiones** como:\n",
                "- El método *Label Propagation* puede ser más rápido, pero a veces más sensible al número de instancias mal etiquetadas.\n",
                "- *Label Spreading* tiende a suavizar la propagación de las etiquetas, lo cual puede ayudar a reducir el ruido.\n",
                "- Si la estructura de los datos forma *clusters* bien diferenciados, estos métodos *graph-based* aprovechan la asunción de que ejemplos cercanos comparten etiqueta.\n",
                "\n",
                "En **prácticas reales**, se pueden probar distintos valores de parámetros (ej. `gamma`, `alpha`, número de vecinos, etc.) y diferentes porcentajes de datos etiquetados (5%, 10%, 20%, etc.) para observar el impacto en el rendimiento."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Conclusiones\n",
                "En esta práctica se han mostrado:\n",
                "1. **Self-Training** como ejemplo de método de clasificación semi-supervisada implementado desde cero.\n",
                "2. Comparaciones de métodos disponibles en **scikit-learn**: *Label Propagation* y *Label Spreading*.\n",
                "\n",
                "### Puntos clave\n",
                "- La **clasificación semi-supervisada** puede brindar mejoras sustanciales cuando se dispone de pocos datos etiquetados y abundantes datos no etiquetados.\n",
                "- Es fundamental **validar** que nuestros supuestos (por ejemplo, \"instancias cercanas tienen la misma etiqueta\") se cumplan de forma razonable.\n",
                "- Añadir datos no etiquetados puede **empeorar** el rendimiento si el modelo realiza asunciones incorrectas.\n",
                "\n",
                "¡Y con esto concluimos la práctica de clasificación semi-supervisada!"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "name": "python"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}