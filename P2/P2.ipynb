{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "title"
      },
      "source": [
        "# **Práctica 2: Clasificación Multi-Instancia**\n",
        "\n",
        "## Opción 2: Comparación de métodos\n",
        "\n",
        "**Objetivo**: Comparar al menos dos algoritmos disponibles en bibliotecas de aprendizaje multi-instancia. Se seleccionan al menos tres conjuntos de datos de tipo multi-instancia para realizar la evaluación y comparación.\n",
        "\n",
        "En este notebook:\n",
        "- Se entrenan dos modelos de clasificación multi-instancia: **MISVM** y **MILES**.\n",
        "- Se usan tres datasets: **Musk1**, **Elephant** y **Corel Dogs**.\n",
        "- Se comparan sus resultados (precisión, F1, AUC y matrices de confusión).\n",
        "- Se presentan conclusiones sobre los hallazgos."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "instalacion"
      },
      "source": [
        "## 1. Instalación de librerías\n",
        "Si usas Google Colab, puedes necesitar instalar las librerías correspondientes. Si ya tienes un entorno con `misvm` y `mil` instalados, puedes omitirlo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "instalacion-code"
      },
      "outputs": [],
      "source": [
        "!pip install git+https://github.com/garydoranjr/misvm.git\n",
        "!pip install numpy scikit-learn scipy tensorflow==2.12.0 mil"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "importaciones"
      },
      "source": [
        "## 2. Importaciones y carga de datos\n",
        "Se importan las librerías necesarias y se cargan los datasets **Musk1**, **Elephant** y **Corel Dogs** a partir de la biblioteca `mil`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "load-data"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "\n",
        "import misvm\n",
        "from mil.data.datasets import loader\n",
        "from mil.bag_representation import MILESMapping\n",
        "from mil.validators import LeaveOneOut\n",
        "from mil.models import SVC\n",
        "from mil.trainer import Trainer\n",
        "from mil.preprocessing import StandarizerBagsList\n",
        "from mil.metrics import AUC\n",
        "\n",
        "print(\"Cargando datasets Musk1, Elephant y Corel Dogs...\")\n",
        "musk1_train, musk1_test = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/musk1.csv')\n",
        "elephant_train, elephant_test = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/elephant.csv')\n",
        "corel_train, corel_test = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/corel_dogs.csv')\n",
        "\n",
        "musk1_bags_train, musk1_y_train = musk1_train\n",
        "musk1_bags_test, musk1_y_test = musk1_test\n",
        "\n",
        "elephant_bags_train, elephant_y_train = elephant_train\n",
        "elephant_bags_test, elephant_y_test = elephant_test\n",
        "\n",
        "corel_bags_train, corel_y_train = corel_train\n",
        "corel_bags_test, corel_y_test = corel_test\n",
        "\n",
        "print(\"Datos cargados correctamente.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "definicion-eval"
      },
      "source": [
        "## 3. Definición de funciones de evaluación\n",
        "En esta sección, definimos:\n",
        "\n",
        "- `evaluate_misvm(...)`: para entrenar y evaluar un clasificador **MISVM** (de la librería [garydoranjr/misvm](https://github.com/garydoranjr/misvm)).\n",
        "- `evaluate_miles(...)`: para entrenar y evaluar un clasificador **MILES** usando la biblioteca [`mil`](https://pypi.org/project/mil/)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "evaluate-functions"
      },
      "outputs": [],
      "source": [
        "def evaluate_misvm(bags_train, y_train, bags_test, y_test, kernel='linear', C=1.0, max_iters=50):\n",
        "    \"\"\"\n",
        "    Entrena y evalúa un clasificador MISVM.\n",
        "    Retorna (accuracy, f1_score, matriz_confusion).\n",
        "    \"\"\"\n",
        "    print(f\"Entrenando MISVM (kernel={kernel}, C={C}, max_iters={max_iters})...\")\n",
        "    classifier = misvm.MISVM(kernel=kernel, C=C, max_iters=max_iters)\n",
        "    y_train_binary = np.array([1 if y > 0 else 0 for y in y_train])\n",
        "    y_test_binary = np.array([1 if y > 0 else 0 for y in y_test])\n",
        "\n",
        "    classifier.fit(bags_train, y_train_binary)\n",
        "    y_pred = classifier.predict(bags_test)\n",
        "\n",
        "    y_pred_binary = np.array([1 if p > 0 else 0 for p in y_pred])\n",
        "\n",
        "    acc = accuracy_score(y_test_binary, y_pred_binary)\n",
        "    f1 = f1_score(y_test_binary, y_pred_binary, zero_division=0)\n",
        "    cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "    return acc, f1, cm\n",
        "\n",
        "def evaluate_miles(bags_train, y_train, bags_test, y_test, kernel='linear', C=1.0):\n",
        "    \"\"\"\n",
        "    Entrena y evalúa MILES utilizando el pipeline de la librería mil.\n",
        "    Retorna (accuracy, auc).\n",
        "    \"\"\"\n",
        "    print(f\"Entrenando MILES (kernel={kernel}, C={C})...\")\n",
        "    trainer = Trainer()\n",
        "    metrics = ['acc', AUC]\n",
        "    model = SVC(kernel=kernel, C=C, class_weight='balanced')\n",
        "    pipeline = [\n",
        "        ('scale', StandarizerBagsList()),\n",
        "        ('disc_mapping', MILESMapping())\n",
        "    ]\n",
        "    trainer.prepare(model, preprocess_pipeline=pipeline, metrics=metrics)\n",
        "\n",
        "    y_train_binary = np.array([1 if y > 0 else 0 for y in y_train])\n",
        "    y_test_binary = np.array([1 if y > 0 else 0 for y in y_test])\n",
        "\n",
        "    valid = LeaveOneOut()\n",
        "\n",
        "    trainer.fit(bags_train, y_train_binary, sample_weights='balanced', validation_strategy=valid, verbose=0)\n",
        "\n",
        "    result = trainer.predict_metrics(bags_test, y_test_binary)\n",
        "    acc = result.get('acc', 0.0)\n",
        "    auc_ = result.get('auc', 0.5)\n",
        "\n",
        "    return acc, auc_\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "experimentos"
      },
      "source": [
        "## 4. Ejecución de experimentos\n",
        "Se evalúan **MISVM** y **MILES** en cada uno de los tres datasets. Al final se grafican las matrices de confusión y se compara el rendimiento de ambos métodos en cada problema."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "run-experiments"
      },
      "outputs": [],
      "source": [
        "print(\"\\n=== Evaluando algoritmos en datasets: Musk1, Elephant, Corel Dogs ===\")\n",
        "\n",
        "misvm_params = {\n",
        "    'kernel': 'rbf',\n",
        "    'C': 10.0,\n",
        "    'max_iters': 50\n",
        "}\n",
        "miles_params = {\n",
        "    'kernel': 'linear',\n",
        "    'C': 1.0\n",
        "}\n",
        "\n",
        "## MISVM ##\n",
        "misvm_musk1 = evaluate_misvm(musk1_bags_train, musk1_y_train, musk1_bags_test, musk1_y_test,\n",
        "                             kernel=misvm_params['kernel'], C=misvm_params['C'], max_iters=misvm_params['max_iters'])\n",
        "misvm_elephant = evaluate_misvm(elephant_bags_train, elephant_y_train, elephant_bags_test, elephant_y_test,\n",
        "                                kernel=misvm_params['kernel'], C=misvm_params['C'], max_iters=misvm_params['max_iters'])\n",
        "misvm_corel = evaluate_misvm(corel_bags_train, corel_y_train, corel_bags_test, corel_y_test,\n",
        "                             kernel=misvm_params['kernel'], C=misvm_params['C'], max_iters=misvm_params['max_iters'])\n",
        "\n",
        "## MILES ##\n",
        "miles_musk1 = evaluate_miles(musk1_bags_train, musk1_y_train, musk1_bags_test, musk1_y_test,\n",
        "                             kernel=miles_params['kernel'], C=miles_params['C'])\n",
        "miles_elephant = evaluate_miles(elephant_bags_train, elephant_y_train, elephant_bags_test, elephant_y_test,\n",
        "                                kernel=miles_params['kernel'], C=miles_params['C'])\n",
        "miles_corel = evaluate_miles(corel_bags_train, corel_y_train, corel_bags_test, corel_y_test,\n",
        "                             kernel=miles_params['kernel'], C=miles_params['C'])\n",
        "\n",
        "print(\"\\n=== Resultados MISVM ===\")\n",
        "print(f\"Musk1 -> Accuracy: {misvm_musk1[0]:.4f}, F1: {misvm_musk1[1]:.4f}\")\n",
        "print(f\"Elephant -> Accuracy: {misvm_elephant[0]:.4f}, F1: {misvm_elephant[1]:.4f}\")\n",
        "print(f\"Corel Dogs -> Accuracy: {misvm_corel[0]:.4f}, F1: {misvm_corel[1]:.4f}\")\n",
        "\n",
        "print(\"\\n=== Resultados MILES ===\")\n",
        "print(f\"Musk1 -> Accuracy: {miles_musk1[0]:.4f}, AUC: {miles_musk1[1]:.4f}\")\n",
        "print(f\"Elephant -> Accuracy: {miles_elephant[0]:.4f}, AUC: {miles_elephant[1]:.4f}\")\n",
        "print(f\"Corel Dogs -> Accuracy: {miles_corel[0]:.4f}, AUC: {miles_corel[1]:.4f}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "matrices-confusion"
      },
      "source": [
        "## 5. Visualización de matrices de confusión (MISVM)\n",
        "Para MILES, calculamos la métrica AUC, pero no obtenemos la matriz de confusión directa en la misma función. Puedes modificar la evaluación de MILES para obtener y mostrar la matriz de confusión si se desea."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "matrices"
      },
      "outputs": [],
      "source": [
        "def plot_confusion_matrix(cm, title):\n",
        "    plt.figure(figsize=(4, 4))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\n=== Matrices de confusión para MISVM ===\")\n",
        "plot_confusion_matrix(misvm_musk1[2], 'Musk1 - MISVM')\n",
        "plot_confusion_matrix(misvm_elephant[2], 'Elephant - MISVM')\n",
        "plot_confusion_matrix(misvm_corel[2], 'Corel Dogs - MISVM')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "comparacion"
      },
      "source": [
        "## 6. Comparación gráfica de la **Accuracy**\n",
        "Se crea una gráfica de barras para comparar la precisión de **MISVM** y **MILES** en cada dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bar-plot"
      },
      "outputs": [],
      "source": [
        "def plot_comparison(datasets, misvm_metrics, miles_metrics, metric_name='Accuracy'):\n",
        "    \"\"\"Crea un diagrama de barras comparando la métrica dada para MISVM y MILES.\"\"\"\n",
        "    misvm_values = [m[0] for m in misvm_metrics]\n",
        "    miles_values = [m[0] for m in miles_metrics]\n",
        "\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(8, 5))\n",
        "    ax.bar(x - width/2, misvm_values, width, label='MISVM')\n",
        "    ax.bar(x + width/2, miles_values, width, label='MILES')\n",
        "\n",
        "    ax.set_ylabel(metric_name)\n",
        "    ax.set_title(f'{metric_name} por algoritmo y dataset')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets)\n",
        "    ax.set_ylim([0, 1])\n",
        "    ax.legend()\n",
        "    plt.show()\n",
        "\n",
        "datasets = ['Musk1', 'Elephant', 'Corel']\n",
        "misvm_results = [misvm_musk1, misvm_elephant, misvm_corel]\n",
        "miles_results = [miles_musk1, miles_elephant, miles_corel]\n",
        "\n",
        "plot_comparison(datasets, misvm_results, miles_results, 'Accuracy')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "conclusiones"
      },
      "source": [
        "## 7. Conclusiones\n",
        "- Hemos comparado dos métodos de clasificación multi-instancia:\n",
        "  - **MISVM** (paradigma basado en SVM a nivel de bolsas)\n",
        "  - **MILES** (basado en mapeo de instancias y SVM).\n",
        "- Se han utilizado tres conjuntos de datos clásicos en MIL: **Musk1**, **Elephant** y **CorelDogs**.\n",
        "- Los resultados muestran diferentes rendimientos en cada dataset. Dependiendo de la complejidad de las bolsas y de la representación, un método puede superar al otro.\n",
        "- **MILES** aporta la ventaja de un mapeo de instancias a un espacio de instancia prototipo, mientras que **MISVM** aprende directamente con las bolsas.\n",
        "- En general, se observa que el comportamiento varía por la naturaleza de los datos. Algunos datasets (p.ej., Musk1) parecen más sencillos para ambos métodos y muestran una mayor **Accuracy**.\n",
        "- Se podrían ajustar más los hiperparámetros (p.ej., tipo de kernel, regularización **C**, etc.) para mejorar los resultados y afinar la comparación.\n",
        "\n",
        "En conclusión, ambos métodos son válidos para problemas de clasificación multi-instancia, pero su rendimiento depende en buena medida de:\n",
        "1. El **tipo de dataset** (características, número de instancias por bolsa, complejidad de la distribución).\n",
        "2. Los **hiperparámetros** escogidos (kernel, C, etc.).\n",
        "3. Técnicas de **preprocesamiento** o **selección de características**."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "P2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython"
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
