{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MarcosRigal/CNC/blob/main/P2/P2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install git+https://github.com/garydoranjr/misvm.git\n",
        "!pip install numpy scikit-learn scipy tensorflow==2.12.0 mil"
      ],
      "metadata": {
        "collapsed": true,
        "id": "qVz3K6BQYOoP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing all the datasets modules\n",
        "from mil.data.datasets import loader\n",
        "\n",
        "# load the datasets\n",
        "(corel_dogs_bags_train, corel_dogs_y_train), (corel_dogs_bags_test, corel_dogs_y_test) = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/corel_dogs.csv')\n",
        "(musk1_bags_train, musk1_y_train), (musk1_bags_test, musk1_y_test) = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/musk1.csv')\n",
        "(elephant_bags_train, elephant_y_train), (elephant_bags_test, elephant_y_test) = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/elephant.csv')"
      ],
      "metadata": {
        "collapsed": true,
        "id": "zJnOAC69Yxhk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import misvm\n",
        "classifier = misvm.MISVM(kernel='linear', C=1.0, max_iters=50)\n",
        "classifier.fit(musk1_bags_train, musk1_y_train)\n",
        "labels = classifier.predict(musk1_bags_test)\n"
      ],
      "metadata": {
        "id": "uXXtZ03meJbE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing bag_representation\n",
        "from mil.bag_representation import MILESMapping\n",
        "# importing validation strategy\n",
        "from mil.validators import LeaveOneOut\n",
        "# importing final model, which in this case is the SVC classifier from sklearn\n",
        "from mil.models import SVC\n",
        "# importing trainer\n",
        "from mil.trainer import Trainer\n",
        "# importing preprocessing\n",
        "from mil.preprocessing import StandarizerBagsList\n",
        "# importing metrics, which in this case are from tf keras metrics\n",
        "from mil.metrics import AUC\n",
        "\n",
        "# instantiate trainer\n",
        "trainer = Trainer()\n",
        "\n",
        "# preparing trainer\n",
        "metrics = ['acc', AUC]\n",
        "model = SVC(kernel='linear', C=1, class_weight='balanced')\n",
        "pipeline = [('scale', StandarizerBagsList()), ('disc_mapping', MILESMapping())]\n",
        "trainer.prepare(model, preprocess_pipeline=pipeline ,metrics=metrics)\n",
        "\n",
        "# fitting trainer\n",
        "valid = LeaveOneOut()\n",
        "history = trainer.fit(musk1_bags_train, musk1_y_train, sample_weights='balanced', validation_strategy=valid, verbose=1)\n",
        "\n",
        "# printing validation results for each fold\n",
        "print(history['metrics_val'])\n",
        "\n",
        "# predicting metrics for the test set\n",
        "trainer.predict_metrics(musk1_bags_test, musk1_y_test)"
      ],
      "metadata": {
        "id": "SCzSrvL2cTVO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
        "from mil.data.datasets import loader\n",
        "import misvm\n",
        "from mil.bag_representation import MILESMapping\n",
        "from mil.validators import LeaveOneOut\n",
        "from mil.models import SVC\n",
        "from mil.trainer import Trainer\n",
        "from mil.preprocessing import StandarizerBagsList\n",
        "from mil.metrics import AUC\n",
        "\n",
        "# Step 1: Load all datasets\n",
        "print(\"Loading datasets...\")\n",
        "# Load Musk1 dataset\n",
        "(musk1_bags_train, musk1_y_train), (musk1_bags_test, musk1_y_test) = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/musk1.csv')\n",
        "# Load Elephant dataset\n",
        "(elephant_bags_train, elephant_y_train), (elephant_bags_test, elephant_y_test) = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/elephant.csv')\n",
        "# Load Corel Dogs dataset\n",
        "(corel_dogs_bags_train, corel_dogs_y_train), (corel_dogs_bags_test, corel_dogs_y_test) = loader.load_data('/usr/local/lib/python3.11/dist-packages/mil/data/datasets/csv/corel_dogs.csv')\n",
        "\n",
        "# Step 2: Define function to evaluate MISVM algorithm\n",
        "def evaluate_misvm(bags_train, y_train, bags_test, y_test, kernel='linear', C=1.0, max_iters=50):\n",
        "    \"\"\"\n",
        "    Evaluate the MISVM algorithm on a dataset\n",
        "\n",
        "    Returns:\n",
        "        accuracy, f1_score, confusion_matrix\n",
        "    \"\"\"\n",
        "    print(f\"Training MISVM with kernel={kernel}, C={C}...\")\n",
        "    classifier = misvm.MISVM(kernel=kernel, C=C, max_iters=max_iters)\n",
        "    classifier.fit(bags_train, y_train)\n",
        "    y_pred = classifier.predict(bags_test)\n",
        "\n",
        "    # Ensure predictions are binary (0 or 1)\n",
        "    y_pred_binary = np.array([1 if pred > 0 else 0 for pred in y_pred])\n",
        "    y_test_binary = np.array([1 if y > 0 else 0 for y in y_test])\n",
        "\n",
        "    # Calculate metrics\n",
        "    acc = accuracy_score(y_test_binary, y_pred_binary)\n",
        "    f1 = f1_score(y_test_binary, y_pred_binary, zero_division=0)\n",
        "    cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "    return acc, f1, cm\n",
        "\n",
        "# Step 3: Define function to evaluate MILES algorithm\n",
        "def evaluate_miles(bags_train, y_train, bags_test, y_test, kernel='linear', C=1.0):\n",
        "    \"\"\"\n",
        "    Evaluate the MILES algorithm on a dataset\n",
        "\n",
        "    Returns:\n",
        "        accuracy, auc\n",
        "    \"\"\"\n",
        "    print(f\"Training MILES with kernel={kernel}, C={C}...\")\n",
        "    # Set up trainer\n",
        "    trainer = Trainer()\n",
        "    metrics = ['acc', AUC]\n",
        "    model = SVC(kernel=kernel, C=C, class_weight='balanced')\n",
        "    pipeline = [('scale', StandarizerBagsList()), ('disc_mapping', MILESMapping())]\n",
        "    trainer.prepare(model, preprocess_pipeline=pipeline, metrics=metrics)\n",
        "\n",
        "    # Convert labels to ensure they're binary (0 or 1)\n",
        "    y_train_binary = np.array([1 if y > 0 else 0 for y in y_train])\n",
        "    y_test_binary = np.array([1 if y > 0 else 0 for y in y_test])\n",
        "\n",
        "    # Train with LOO validation\n",
        "    valid = LeaveOneOut()\n",
        "    try:\n",
        "        history = trainer.fit(bags_train, y_train_binary, sample_weights='balanced', validation_strategy=valid, verbose=0)\n",
        "        # Test metrics\n",
        "        result = trainer.predict_metrics(bags_test, y_test_binary)\n",
        "        # Return accuracy and AUC\n",
        "        return result['acc'], result.get('auc', 0.5)  # Default AUC to 0.5 if not available\n",
        "    except Exception as e:\n",
        "        print(f\"Error training MILES: {e}\")\n",
        "        # Return default values\n",
        "        return 0.0, 0.5\n",
        "\n",
        "def evaluate_misvm(bags_train, y_train, bags_test, y_test, kernel='linear', C=1.0):\n",
        "    \"\"\"\n",
        "    Evaluate the MISVM algorithm on a dataset\n",
        "\n",
        "    Returns:\n",
        "        accuracy, f1_score, confusion_matrix\n",
        "    \"\"\"\n",
        "    print(f\"Training MISVM with kernel={kernel}, C={C}...\")\n",
        "    classifier = misvm.MISVM(kernel=kernel, C=C)\n",
        "\n",
        "    # Ensure labels are binary (0 or 1)\n",
        "    y_train_binary = np.array([1 if y > 0 else 0 for y in y_train])\n",
        "    y_test_binary = np.array([1 if y > 0 else 0 for y in y_test])\n",
        "\n",
        "    try:\n",
        "        classifier.fit(bags_train, y_train_binary)\n",
        "        y_pred = classifier.predict(bags_test)\n",
        "\n",
        "        # Ensure predictions are binary (0 or 1)\n",
        "        y_pred_binary = np.array([1 if pred > 0 else 0 for pred in y_pred])\n",
        "\n",
        "        # Calculate metrics\n",
        "        acc = accuracy_score(y_test_binary, y_pred_binary)\n",
        "        f1 = f1_score(y_test_binary, y_pred_binary, zero_division=0)\n",
        "        cm = confusion_matrix(y_test_binary, y_pred_binary)\n",
        "\n",
        "        return acc, f1, cm\n",
        "    except Exception as e:\n",
        "        print(f\"Error training MISVM: {e}\")\n",
        "        # Return default values\n",
        "        return 0.0, 0.0, np.array([[0, 0], [0, 0]])\n",
        "\n",
        "print(\"\\nEvaluating algorithms on all datasets...\")\n",
        "misvm_musk1 = evaluate_misvm(musk1_bags_train, musk1_y_train, musk1_bags_test, musk1_y_test, kernel='rbf', C=10.0)\n",
        "misvm_elephant = evaluate_misvm(elephant_bags_train, elephant_y_train, elephant_bags_test, elephant_y_test, kernel='rbf', C=10.0)\n",
        "misvm_corel_dogs = evaluate_misvm(corel_dogs_bags_train, corel_dogs_y_train, corel_dogs_bags_test, corel_dogs_y_test, kernel='rbf', C=10.0)\n",
        "miles_musk1 = evaluate_miles(musk1_bags_train, musk1_y_train, musk1_bags_test, musk1_y_test, kernel='linear', C=1.0)\n",
        "miles_elephant = evaluate_miles(elephant_bags_train, elephant_y_train, elephant_bags_test, elephant_y_test, kernel='linear', C=1.0)\n",
        "miles_corel_dogs = evaluate_miles(corel_dogs_bags_train, corel_dogs_y_train, corel_dogs_bags_test, corel_dogs_y_test, kernel='linear', C=1.0)\n",
        "\n",
        "# Step 6: Visualize Results\n",
        "def plot_confusion_matrix(cm, title):\n",
        "    \"\"\"Plot a confusion matrix\"\"\"\n",
        "    plt.figure(figsize=(6, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')\n",
        "    plt.title(title)\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')\n",
        "    plt.show()\n",
        "\n",
        "print(\"\\nPlotting confusion matrices...\")\n",
        "plot_confusion_matrix(misvm_musk1[2], 'MISVM Musk1 Confusion Matrix')\n",
        "plot_confusion_matrix(misvm_elephant[2], 'MISVM Elephant Confusion Matrix')\n",
        "plot_confusion_matrix(misvm_corel_dogs[2], 'MISVM Corel Dogs Confusion Matrix')\n",
        "\n",
        "# Step 7: Compare Metrics\n",
        "def compare_misvm_miles(misvm_results, miles_results, dataset_name):\n",
        "    \"\"\"Compare metrics between algorithms\"\"\"\n",
        "    print(f\"\\nDataset: {dataset_name}\")\n",
        "    print(f\"MISVM Accuracy: {misvm_results[0]:.4f}, F1 Score: {misvm_results[1]:.4f}\")\n",
        "    print(f\"MILES Accuracy: {miles_results[0]:.4f}, AUC: {miles_results[1]:.4f}\")\n",
        "\n",
        "# Compare metrics\n",
        "compare_misvm_miles(misvm_musk1, miles_musk1, 'Musk1')\n",
        "compare_misvm_miles(misvm_elephant, miles_elephant, 'Elephant')\n",
        "compare_misvm_miles(misvm_corel_dogs, miles_corel_dogs, 'Corel Dogs')\n",
        "\n",
        "# Step 8: Create a bar chart to compare algorithm performance\n",
        "def plot_comparison(datasets, misvm_metrics, miles_metrics, metric_name='Accuracy'):\n",
        "    \"\"\"Create a bar chart comparing algorithm performance\"\"\"\n",
        "    misvm_values = [m[0] for m in misvm_metrics]  # Use accuracy for MISVM\n",
        "    miles_values = [m[0] for m in miles_metrics]  # Use accuracy for MILES\n",
        "\n",
        "    x = np.arange(len(datasets))\n",
        "    width = 0.35\n",
        "\n",
        "    fig, ax = plt.subplots(figsize=(10, 6))\n",
        "    ax.bar(x - width/2, misvm_values, width, label='MISVM')\n",
        "    ax.bar(x + width/2, miles_values, width, label='MILES')\n",
        "\n",
        "    ax.set_ylabel(metric_name)\n",
        "    ax.set_title(f'{metric_name} by Algorithm and Dataset')\n",
        "    ax.set_xticks(x)\n",
        "    ax.set_xticklabels(datasets)\n",
        "    ax.legend()\n",
        "\n",
        "    plt.ylim(0, 1)\n",
        "    plt.show()\n",
        "\n",
        "# Plot accuracy comparison\n",
        "print(\"\\nPlotting accuracy comparison...\")\n",
        "plot_comparison(['Musk1', 'Elephant', 'Corel Dogs'],\n",
        "                [misvm_musk1, misvm_elephant, misvm_corel_dogs],\n",
        "                [miles_musk1, miles_elephant, miles_corel_dogs],\n",
        "                'Accuracy')\n",
        "\n",
        "# Step 9: Generate summary of findings\n",
        "print(\"\\n=== SUMMARY OF FINDINGS ===\")\n",
        "print(\"1. Algorithm Performance Comparison:\")\n",
        "print(\"   - MISVM:\")\n",
        "musk1_acc, elephant_acc, corel_acc = misvm_musk1[0], misvm_elephant[0], misvm_corel_dogs[0]\n",
        "print(f\"     Musk1: {musk1_acc:.4f}, Elephant: {elephant_acc:.4f}, Corel Dogs: {corel_acc:.4f}\")\n",
        "print(f\"     Average accuracy: {np.mean([musk1_acc, elephant_acc, corel_acc]):.4f}\")\n",
        "\n",
        "print(\"   - MILES:\")\n",
        "musk1_acc, elephant_acc, corel_acc = miles_musk1[0], miles_elephant[0], miles_corel_dogs[0]\n",
        "print(f\"     Musk1: {musk1_acc:.4f}, Elephant: {elephant_acc:.4f}, Corel Dogs: {corel_acc:.4f}\")\n",
        "print(f\"     Average accuracy: {np.mean([musk1_acc, elephant_acc, corel_acc]):.4f}\")\n",
        "\n",
        "print(\"\\n2. Dataset Difficulty Analysis:\")\n",
        "datasets = ['Musk1', 'Elephant', 'Corel Dogs']\n",
        "misvm_accs = [misvm_musk1[0], misvm_elephant[0], misvm_corel_dogs[0]]\n",
        "miles_accs = [miles_musk1[0], miles_elephant[0], miles_corel_dogs[0]]\n",
        "avg_accs = [(m + n)/2 for m, n in zip(misvm_accs, miles_accs)]\n",
        "\n",
        "# Sort datasets by difficulty (lower accuracy = more difficult)\n",
        "difficulty_order = np.argsort(avg_accs)\n",
        "for i in difficulty_order:\n",
        "    print(f\"   - {datasets[i]}: Average accuracy {avg_accs[i]:.4f}\")\n",
        "\n",
        "print(\"\\n3. Conclusions:\")\n",
        "if np.mean(misvm_accs) > np.mean(miles_accs):\n",
        "    print(\"   - MISVM performed better overall, suggesting it's more suitable for these datasets.\")\n",
        "elif np.mean(misvm_accs) < np.mean(miles_accs):\n",
        "    print(\"   - MILES performed better overall, suggesting it's more suitable for these datasets.\")\n",
        "else:\n",
        "    print(\"   - Both algorithms performed similarly overall, but showed different strengths on specific datasets.\")\n",
        "\n",
        "print(\"   - The datasets vary in difficulty, with some datasets being more challenging for both algorithms.\")\n",
        "print(\"   - Hyperparameter tuning and additional feature engineering could potentially improve results further.\")"
      ],
      "metadata": {
        "id": "sMyFcKzciU6f",
        "outputId": "ba94f814-c416-48fc-8b3e-d6727fd8550b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loading datasets...\n",
            "\n",
            "Evaluating algorithms on all datasets...\n",
            "Training MISVM with kernel=rbf, C=10.0...\n",
            "Non-random start...\n",
            "\n",
            "Iteration 1...\n",
            "Training SVM...\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.7928e+01 -1.0764e+01  7e+02  3e+01  2e-16\n",
            " 1: -5.0527e+00 -6.6788e+00  2e+01  7e-01  9e-16\n",
            " 2: -3.0290e+00 -5.0573e+00  2e+00  5e-16  4e-16\n",
            " 3: -3.1239e+00 -3.2443e+00  1e-01  6e-16  2e-16\n",
            " 4: -3.1245e+00 -3.1284e+00  4e-03  9e-16  2e-16\n",
            " 5: -3.1250e+00 -3.1253e+00  2e-04  6e-16  2e-16\n",
            " 6: -3.1251e+00 -3.1251e+00  2e-06  8e-17  5e-17\n",
            "Optimal solution found.\n",
            "Recomputing classes...\n",
            "Selector differences: 227\n",
            "Updating QP...\n",
            "\n",
            "Iteration 2...\n",
            "Training SVM...\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -2.7928e+01 -1.0764e+01  7e+02  3e+01  2e-16\n",
            " 1: -5.0527e+00 -6.6788e+00  2e+01  7e-01  9e-16\n",
            " 2: -3.0290e+00 -5.0573e+00  2e+00  5e-16  4e-16\n",
            " 3: -3.1239e+00 -3.2443e+00  1e-01  6e-16  2e-16\n",
            " 4: -3.1245e+00 -3.1284e+00  4e-03  9e-16  2e-16\n",
            " 5: -3.1250e+00 -3.1253e+00  2e-04  6e-16  2e-16\n",
            " 6: -3.1251e+00 -3.1251e+00  2e-06  8e-17  5e-17\n",
            "Optimal solution found.\n",
            "Recomputing classes...\n",
            "Selector differences: 0\n",
            "Training MISVM with kernel=rbf, C=10.0...\n",
            "Non-random start...\n",
            "\n",
            "Iteration 1...\n",
            "Training SVM...\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -6.4241e+01 -1.5746e+01  2e+03  4e+01  3e-16\n",
            " 1: -7.5925e+00 -6.0737e+00  6e+01  1e+00  6e-16\n",
            " 2: -2.6195e+00 -5.4607e+00  3e+00  4e-16  9e-16\n",
            " 3: -2.7249e+00 -2.8643e+00  1e-01  5e-16  5e-16\n",
            " 4: -2.7314e+00 -2.7372e+00  6e-03  2e-16  4e-16\n",
            " 5: -2.7318e+00 -2.7346e+00  3e-03  4e-17  3e-15\n",
            " 6: -2.7321e+00 -2.7332e+00  1e-03  2e-16  4e-15\n",
            " 7: -2.7322e+00 -2.7324e+00  2e-04  5e-17  9e-16\n",
            " 8: -2.7322e+00 -2.7323e+00  2e-05  4e-16  4e-15\n",
            " 9: -2.7322e+00 -2.7322e+00  6e-07  2e-16  6e-15\n",
            "Optimal solution found.\n",
            "Recomputing classes...\n",
            "Selector differences: 568\n",
            "Updating QP...\n",
            "\n",
            "Iteration 2...\n",
            "Training SVM...\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -6.4907e+01 -1.5638e+01  2e+03  4e+01  3e-16\n",
            " 1: -7.4227e+00 -6.0604e+00  6e+01  1e+00  6e-16\n",
            " 2: -2.6211e+00 -5.4387e+00  3e+00  7e-16  9e-16\n",
            " 3: -2.7254e+00 -2.8732e+00  1e-01  7e-16  6e-16\n",
            " 4: -2.7320e+00 -2.7365e+00  5e-03  2e-16  4e-16\n",
            " 5: -2.7324e+00 -2.7336e+00  1e-03  4e-17  2e-15\n",
            " 6: -2.7325e+00 -2.7328e+00  2e-04  2e-16  3e-15\n",
            " 7: -2.7326e+00 -2.7326e+00  5e-06  1e-16  1e-15\n",
            " 8: -2.7326e+00 -2.7326e+00  5e-08  5e-16  8e-16\n",
            "Optimal solution found.\n",
            "Recomputing classes...\n",
            "Selector differences: 0\n",
            "Training MISVM with kernel=rbf, C=10.0...\n",
            "Non-random start...\n",
            "\n",
            "Iteration 1...\n",
            "Training SVM...\n",
            "     pcost       dcost       gap    pres   dres\n",
            " 0: -7.9509e+01 -1.5885e+01  3e+04  2e+02  1e-15\n",
            " 1: -1.1393e+01 -6.1170e+00  2e+03  1e+01  7e-16\n",
            " 2: -7.7116e-01 -4.9847e+00  1e+02  6e-01  1e-15\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}