{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "141ae917",
   "metadata": {},
   "source": [
    "# Práctica 4: Clasificación Semi-Supervisada\n",
    "\n",
    "**Objetivo**: El objetivo de esta práctica es introducir los conceptos de clasificación semi-supervisada.\n",
    "\n",
    "La práctica consiste en dos tareas:\n",
    "\n",
    "## TAREA 1: Implementación de un método\n",
    "- Seleccione un algoritmo de los indicados en la teoría que implemente aprendizaje semi-supervisado de cualquiera de los paradigmas estudiados.\n",
    "- Implemente el algoritmo.\n",
    "- Seleccione al menos un dataset semi-supervisado y evalúe el algoritmo implementado.\n",
    "\n",
    "## TAREA 2: Comparación de métodos\n",
    "1. Seleccione al menos dos algoritmos de los disponibles en las bibliotecas indicadas.\n",
    "2. Seleccione al menos tres problemas semi-supervisados de los repositorios indicados.\n",
    "3. Aplique los algoritmos seleccionados a los datasets.\n",
    "4. Compare los resultados y explique las conclusiones obtenidas.\n",
    "\n",
    "En este notebook se incluye un ejemplo con dos tareas:\n",
    "1. **Tarea 1**: Implementación y uso de un método de Self-Training.\n",
    "2. **Tarea 2**: Comparación de Label Spreading y Self-Training sobre datasets generados sintéticamente.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "250ba426",
   "metadata": {},
   "source": [
    "## TAREA 1: Implementación de un método de Self-Training\n",
    "\n",
    "En esta celda se muestra la implementación de un algoritmo de *Self-Training* desde cero y su posterior evaluación en un dataset sintético. Se entrena un modelo con un pequeño subconjunto etiquetado y se itera sobre instancias no etiquetadas, pseudo-etiquetándolas de forma progresiva si el modelo está suficientemente seguro (superando un determinado umbral de confianza)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c42bd4e",
   "metadata": {
    "colab": {},
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.base import clone\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "def self_training(X_labeled, y_labeled, X_unlabeled, base_classifier,\n",
    "                  confidence_threshold=0.9, max_iter=10):\n",
    "    \"\"\"\n",
    "    Self-Training method.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X_labeled : array-like, shape (n_labeled_samples, n_features)\n",
    "        Labeled dataset.\n",
    "    y_labeled : array-like, shape (n_labeled_samples,)\n",
    "        Corresponding labels for X_labeled.\n",
    "    X_unlabeled : array-like, shape (n_unlabeled_samples, n_features)\n",
    "        Unlabeled dataset.\n",
    "    base_classifier : scikit-learn estimator\n",
    "        Base classifier that must support at least the `predict_proba` method.\n",
    "        (If it does not support `predict_proba`, confidence is assumed to be 1 for all instances).\n",
    "    confidence_threshold : float, optional (default=0.9)\n",
    "        Minimum probability threshold to accept pseudo-labeled instances.\n",
    "    max_iter : int, optional (default=10)\n",
    "        Maximum number of self-training iterations.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    trained_classifier : scikit-learn estimator\n",
    "        The trained classifier at the end of the process (or after exhausting\n",
    "        the unlabeled instances that meet the confidence threshold).\n",
    "    \"\"\"\n",
    "\n",
    "    # Copies to avoid modifying the original data\n",
    "    X_l = X_labeled.copy()\n",
    "    y_l = y_labeled.copy()\n",
    "    X_u = X_unlabeled.copy()\n",
    "\n",
    "    for i in range(1, max_iter + 1):\n",
    "        # Create/Clone the classifier to train it from scratch in each iteration\n",
    "        current_clf = clone(base_classifier)\n",
    "        current_clf.fit(X_l, y_l)\n",
    "\n",
    "        # If the classifier has predict_proba, use it to calculate confidence\n",
    "        if hasattr(current_clf, \"predict_proba\"):\n",
    "            probs = current_clf.predict_proba(X_u)\n",
    "            pred_labels = np.argmax(probs, axis=1)\n",
    "            max_probs = np.max(probs, axis=1)\n",
    "        else:\n",
    "            # If it does not have predict_proba, use predict and assume confidence=1\n",
    "            pred_labels = current_clf.predict(X_u)\n",
    "            max_probs = np.ones(len(X_u))\n",
    "\n",
    "        # Select instances with confidence >= confidence_threshold\n",
    "        high_conf_idx = np.where(max_probs >= confidence_threshold)[0]\n",
    "\n",
    "        if len(high_conf_idx) == 0:\n",
    "            print(f\"Iteration {i}: No instances found with confidence >= {confidence_threshold}. Ending.\")\n",
    "            break\n",
    "\n",
    "        # Add to the labeled dataset\n",
    "        X_l = np.vstack([X_l, X_u[high_conf_idx]])\n",
    "        y_l = np.hstack([y_l, pred_labels[high_conf_idx]])\n",
    "\n",
    "        # Remove from the unlabeled dataset\n",
    "        X_u = np.delete(X_u, high_conf_idx, axis=0)\n",
    "\n",
    "        print(f\"Iteration {i}: Added {len(high_conf_idx)} high-confidence instances.\")\n",
    "\n",
    "        # If no more unlabeled examples remain, end\n",
    "        if len(X_u) == 0:\n",
    "            print(f\"Iteration {i}: No more unlabeled instances remaining. Ending.\")\n",
    "            break\n",
    "\n",
    "    # Train a final classifier with all accumulated labeled data\n",
    "    final_clf = clone(base_classifier)\n",
    "    final_clf.fit(X_l, y_l)\n",
    "\n",
    "    return final_clf\n",
    "\n",
    "# Example usage with synthetic data\n",
    "if __name__ == \"__main__\":\n",
    "    from sklearn.datasets import make_classification\n",
    "    from sklearn.model_selection import train_test_split\n",
    "    from sklearn.metrics import accuracy_score\n",
    "\n",
    "    # Generate synthetic dataset\n",
    "    X, y = make_classification(n_samples=1000, n_features=10,\n",
    "                               n_informative=3, n_classes=2,\n",
    "                               random_state=42)\n",
    "\n",
    "    # Split into train/test sets\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "                                                        test_size=0.3,\n",
    "                                                        random_state=42)\n",
    "\n",
    "    # Take only 20% of y_train as labeled\n",
    "    labeled_percentage = 0.2\n",
    "    num_labeled = int(len(y_train) * labeled_percentage)\n",
    "    X_labeled = X_train[:num_labeled]\n",
    "    y_labeled = y_train[:num_labeled]\n",
    "\n",
    "    # The rest is considered unlabeled\n",
    "    X_unlabeled = X_train[num_labeled:]\n",
    "\n",
    "    # Train using Self-Training with a RandomForest\n",
    "    rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    self_trained_model = self_training(\n",
    "        X_labeled,\n",
    "        y_labeled,\n",
    "        X_unlabeled,\n",
    "        rf,\n",
    "        confidence_threshold=0.9,\n",
    "        max_iter=10\n",
    "    )\n",
    "\n",
    "    # Evaluate on the test set\n",
    "    y_pred = self_trained_model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    print(\"Test accuracy after Self-Training:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40be4cf6",
   "metadata": {},
   "source": [
    "## TAREA 2: Comparación de Label Spreading y Self-Training\n",
    "\n",
    "En la siguiente celda se ilustra cómo comparar dos métodos de clasificación semi-supervisada (Label Spreading y Self-Training) en al menos dos datasets sintéticos. En una entrega final, pueden agregarse más datasets o reemplazar estos por otros de repositorios reconocidos, tal como lo solicita la consigna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63099e63",
   "metadata": {
    "colab": {},
    "executionInfo": {}
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, f1_score, confusion_matrix\n",
    "from sklearn.semi_supervised import LabelSpreading, SelfTrainingClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.datasets import make_moons, make_classification\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "# Generate synthetic semi-supervised datasets\n",
    "def generate_datasets():\n",
    "    datasets = {}\n",
    "\n",
    "    # Dataset 1: Moons dataset (easy clustering structure)\n",
    "    X_moons, y_moons = make_moons(n_samples=300, noise=0.2, random_state=42)\n",
    "    # Remove labels from 70% of the data\n",
    "    y_moons[np.random.choice(len(y_moons), size=int(0.7 * len(y_moons)), replace=False)] = -1\n",
    "    datasets[\"Moons\"] = (X_moons, y_moons)\n",
    "\n",
    "    # Dataset 2: More complex synthetic classification dataset\n",
    "    X_class, y_class = make_classification(n_samples=500, n_features=20, n_informative=15, \n",
    "                                          n_clusters_per_class=1, random_state=42)\n",
    "    # Remove labels from 60% of the data\n",
    "    y_class[np.random.choice(len(y_class), size=int(0.6 * len(y_class)), replace=False)] = -1\n",
    "    datasets[\"Complex Classification\"] = (X_class, y_class)\n",
    "\n",
    "    return datasets\n",
    "\n",
    "# Define evaluation function\n",
    "def evaluate_semi_supervised(model, X, y, dataset_name):\n",
    "    # Only use labeled data for training/testing splits\n",
    "    labeled_mask = y != -1  # Identify labeled data\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X[labeled_mask], y[labeled_mask], \n",
    "                                                        test_size=0.3, random_state=42)\n",
    "\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    acc = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred)\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "    print(f\"Dataset: {dataset_name}\")\n",
    "    print(f\"Accuracy: {acc:.4f}, F1 Score: {f1:.4f}\\n\")\n",
    "    return acc, f1, cm\n",
    "\n",
    "# Load datasets\n",
    "datasets = generate_datasets()\n",
    "\n",
    "# Initialize models\n",
    "label_spreading = LabelSpreading(kernel='knn', n_neighbors=5)\n",
    "self_training = SelfTrainingClassifier(estimator=SVC(probability=True), max_iter=10)\n",
    "\n",
    "# Evaluate models\n",
    "results = {}\n",
    "for dataset_name, (X, y) in datasets.items():\n",
    "    print(f\"Evaluating {dataset_name} with Label Spreading\")\n",
    "    results[(dataset_name, 'Label Spreading')] = evaluate_semi_supervised(label_spreading, X, y, dataset_name)\n",
    "\n",
    "    print(f\"Evaluating {dataset_name} with Self-Training\")\n",
    "    results[(dataset_name, 'Self-Training')] = evaluate_semi_supervised(self_training, X, y, dataset_name)\n",
    "\n",
    "# Plot accuracy comparison\n",
    "dataset_names = list(datasets.keys())\n",
    "methods = ['Label Spreading', 'Self-Training']\n",
    "accuracies = np.array([[results[(ds, method)][0] for method in methods] for ds in dataset_names])\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "x = np.arange(len(dataset_names))\n",
    "width = 0.35\n",
    "ax.bar(x - width/2, accuracies[:, 0], width, label='Label Spreading')\n",
    "ax.bar(x + width/2, accuracies[:, 1], width, label='Self-Training')\n",
    "ax.set_ylabel('Accuracy')\n",
    "ax.set_title('Comparison of Semi-Supervised Learning Methods')\n",
    "ax.set_xticks(x)\n",
    "ax.set_xticklabels(dataset_names)\n",
    "ax.legend()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b645035",
   "metadata": {},
   "source": [
    "### Conclusiones y Tareas Pendientes\n",
    "- Se ha mostrado cómo implementar un esquema de **Self-Training** manualmente y cómo comparar con el método **Label Spreading**.\n",
    "- Para una práctica más completa, se recomienda:\n",
    "  1. Probar ambos algoritmos (o más) en *tres o más* datasets, preferentemente tomados de repositorios públicos o con distintas características.\n",
    "  2. Analizar la sensibilidad a distintos porcentajes de instancias no etiquetadas (variar el porcentaje de eliminación de etiquetas).\n",
    "  3. Ajustar hiperparámetros (e.g., `confidence_threshold` en Self-Training, `n_neighbors` en LabelSpreading) para ver qué configuraciones obtienen mejores resultados.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.8"
  },
  "name": "assignment"
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
